{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP: Assignment 1 \n",
    "\n",
    "### Description of Assignment 1\n",
    "\n",
    "This assignment relates to Theme Basic NLP of the introduction to NLP (courses Deskriptiv analytik / Machine learning for descriptive problems), and will focus on basic text processing methods on Python.\n",
    "\n",
    "The assignment is handed in as a Jupyter notebook containing the code used to solve the problem, output presenting the results, and, most importantly, notes that present the students' conclusions and answer questions posed in the assignment. \n",
    "\n",
    "**Assignment steps/Questions:**\n",
    "\n",
    "Download and extract data package from here [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz). Gzipped file intro-to-nlp/english-tweets-sample.jsonl.gz includes 10,000 English tweets downloaded from the Twiter API. The file is compressed and in JSON Lines format ([http://jsonlines.org/](http://jsonlines.org/)), i.e. one json per line.\n",
    "\n",
    "Note: If processing the whole fiel takes too long, it's okay to read just a subset of the data, for example only 2,000 tweets...\n",
    "\n",
    "1. Read tweets in Python \n",
    "2. Extract the actual text fields from the tweet jsons, discard all metadata at this point. Note that sometimes the text may be truncated to fit the old character limit. In these cases, is it possible to get the full text?\n",
    "3. Segment each tweet using both UDPipe machine learned model (can be found from the same data package) and a heuristic method. What can you tell about the segmentation performance on tweets when manually inspecting few examples?\n",
    "4. Count a word frequency list (how many times each word appears and how many unique words there are). Which are the most commmon words appearing in the data? What kind of words these are?\n",
    "5. Calculate **idf** weight for each word appearing in the data (one tweet = one document), and print top 20 words with lowest and highest idf values. Why **tf** not really matter when processing tweets?\n",
    "6. Find duplicate or near duplicate tweets (in terms of text field only) in the data using any method you see fit. What kind of techniques you considered using and/or tested, and how many duplicate or near duplicate did you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Niklas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "import ufal.udpipe as udpipe\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords') # download the stopwords dataset\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read tweets in Python \n",
    "\n",
    "Let's start by reading in the tweets from the gzipped jsonline file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from gzip file and decode the json to a list \n",
    "\n",
    "#import json\n",
    "#import gzip\n",
    "\n",
    "data = []\n",
    "with gzip.open('english-tweets-sample.jsonl.gz', 'rb')as f:\n",
    "    for line in f:        \n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10000\n",
      "Data type: <class 'list'>\n",
      "First item type: <class 'dict'>\n",
      "First item: {'created_at': 'Tue Dec 26 14:16:22 +0000 2017', 'id': 945659557480611840, 'id_str': '945659557480611840', 'text': 'Check out my class in #GranblueFantasy! https://t.co/pAvXn8diJr', 'display_text_range': [0, 39], 'source': '<a href=\"http://granbluefantasy.jp/\" rel=\"nofollow\">„Ç∞„É©„É≥„Éñ„É´„Éº „Éï„Ç°„É≥„Çø„Ç∏„Éº</a>', 'truncated': False, 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 883980236655779840, 'id_str': '883980236655779840', 'name': 'Pc Kwok', 'screen_name': 'jensenpck', 'location': None, 'url': None, 'description': None, 'translator_type': 'none', 'protected': False, 'verified': False, 'followers_count': 0, 'friends_count': 1, 'listed_count': 0, 'favourites_count': 0, 'statuses_count': 42, 'created_at': 'Sun Jul 09 09:24:46 +0000 2017', 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'lang': 'zh-tw', 'contributors_enabled': False, 'is_translator': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': '', 'profile_background_image_url_https': '', 'profile_background_tile': False, 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'default_profile': True, 'default_profile_image': False, 'following': None, 'follow_request_sent': None, 'notifications': None}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'quote_count': 0, 'reply_count': 0, 'retweet_count': 0, 'favorite_count': 0, 'entities': {'hashtags': [{'text': 'GranblueFantasy', 'indices': [22, 38]}], 'urls': [], 'user_mentions': [], 'symbols': [], 'media': [{'id': 945659555123404801, 'id_str': '945659555123404801', 'indices': [40, 63], 'media_url': 'http://pbs.twimg.com/media/DR-oWuWVoAEUZJd.jpg', 'media_url_https': 'https://pbs.twimg.com/media/DR-oWuWVoAEUZJd.jpg', 'url': 'https://t.co/pAvXn8diJr', 'display_url': 'pic.twitter.com/pAvXn8diJr', 'expanded_url': 'https://twitter.com/jensenpck/status/945659557480611840/photo/1', 'type': 'photo', 'sizes': {'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1024, 'h': 512, 'resize': 'fit'}, 'large': {'w': 1024, 'h': 512, 'resize': 'fit'}}}]}, 'extended_entities': {'media': [{'id': 945659555123404801, 'id_str': '945659555123404801', 'indices': [40, 63], 'media_url': 'http://pbs.twimg.com/media/DR-oWuWVoAEUZJd.jpg', 'media_url_https': 'https://pbs.twimg.com/media/DR-oWuWVoAEUZJd.jpg', 'url': 'https://t.co/pAvXn8diJr', 'display_url': 'pic.twitter.com/pAvXn8diJr', 'expanded_url': 'https://twitter.com/jensenpck/status/945659557480611840/photo/1', 'type': 'photo', 'sizes': {'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'medium': {'w': 1024, 'h': 512, 'resize': 'fit'}, 'large': {'w': 1024, 'h': 512, 'resize': 'fit'}}}]}, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'filter_level': 'low', 'lang': 'en', 'timestamp_ms': '1514297782665'}\n"
     ]
    }
   ],
   "source": [
    "# Show information of the data\n",
    "print(\"Number of documents:\", len(data))\n",
    "print(\"Data type:\", type(data))\n",
    "print(\"First item type:\", type(data[0]))\n",
    "print(\"First item:\", data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract the actual text fields from the tweet jsons\n",
    "\n",
    "**Extract the actual text fields from the tweet jsons, discard all metadata at this point. Note that sometimes the text may be truncated to fit the old character limit. In these cases, is it possible to get the full text?**\n",
    "\n",
    "Let's start by extracting only the text fields from the tweets. Some of the tweets are truncated and yes it is possible to extract the full text from truncated tweets. \n",
    "\n",
    "There are two kind of truncated texts:\n",
    "1. Original tweets that are truncated. (Value of truncated == True)\n",
    "2. Retweeted tweets that are truncated. \n",
    "\n",
    "The retweeted tweets do not say from the truncated status if they are truncated. From the retweeted_status it is possible to check if the original tweet has been truncated and to extract the full_text tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the actual text field an ddiscard meta data\n",
    "documents = []\n",
    "\n",
    "for d in data:\n",
    "    # Check if retweeted\n",
    "    if(\"retweeted_status\" in d):\n",
    "        # Check if retweet is truncated\n",
    "        if(d[\"retweeted_status\"][\"truncated\"] == True):\n",
    "            documents.append(d[\"retweeted_status\"][\"extended_tweet\"][\"full_text\"])    \n",
    "        else:\n",
    "            documents.append(d[\"retweeted_status\"][\"text\"])\n",
    "    # Check if original tweet is truncated                \n",
    "    elif(d[\"truncated\"] == True): \n",
    "        documents.append(d[\"extended_tweet\"][\"full_text\"])\n",
    "    # Default case\n",
    "    else:\n",
    "        documents.append(d[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10000\n",
      "Documents type: <class 'list'>\n",
      "First item type: <class 'str'>\n",
      "First item: Check out my class in #GranblueFantasy! https://t.co/pAvXn8diJr\n",
      "Second item: Extending a big Thank You to our Community Partner all over the world! https://t.co/cu7on7g1si\n",
      "Third item: Blueberry üç® https://t.co/2gzHAFWYJY\n"
     ]
    }
   ],
   "source": [
    "# Show information of the data\n",
    "print(\"Number of documents:\", len(documents))\n",
    "print(\"Documents type:\", type(documents))\n",
    "print(\"First item type:\", type(documents[0]))\n",
    "print(\"First item:\", documents[0])\n",
    "print(\"Second item:\", documents[1])\n",
    "print(\"Third item:\", documents[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segment each tweet using both UDPipe machine learned model and a heuristic method\n",
    "\n",
    "**Segment each tweet using both UDPipe machine learned model (can be found from the same data package) and a heuristic method. What can you tell about the segmentation performance on tweets when manually inspecting few examples?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation with UDPipe machine learned model\n",
    "\n",
    "#import ufal.udpipe as udpipe\n",
    "\n",
    "model = udpipe.Model.load(\"en.segmenter.udpipe\")\n",
    "pipeline = udpipe.Pipeline(model,\"tokenize\",\"none\",\"none\",\"horizontal\")\n",
    "\n",
    "segmented_documents = []\n",
    "\n",
    "for d in documents:\n",
    "    segmented_documents.append(pipeline.process(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check out my class in # GranblueFantasy !\\nhtt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extending a big Thank\\nYou to our Community Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blueberry üç® https://t.co/2gzHAFWYJY\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad day ‚òπÔ∏è¬ÆÔ∏è\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@prologve_ @BTS_ARMY @BTS_twt I 'm Chim tho\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  Check out my class in # GranblueFantasy !\\nhtt...\n",
       "1  Extending a big Thank\\nYou to our Community Pa...\n",
       "2              Blueberry üç® https://t.co/2gzHAFWYJY\\n\n",
       "3                                     Bad day ‚òπÔ∏è¬ÆÔ∏è\\n\n",
       "4      @prologve_ @BTS_ARMY @BTS_twt I 'm Chim tho\\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data\n",
    "df = pd.DataFrame({'Tweets':segmented_documents})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation with a heuristic model\n",
    "\n",
    "#import re\n",
    "\n",
    "heuristic_seg_docs = []\n",
    "\n",
    "for d in documents:\n",
    "    segmented = re.sub(r'https?:\\/\\/.*\\/\\w*', '', d) #remove links\n",
    "    segmented = re.sub(r'@[^\\s]+', '', segmented) #remove twitter handles\n",
    "    segmented = re.sub(r'#[^\\s]+', '', segmented) #remove hashtags\n",
    "    segmented = re.sub(r'(&.+;)', '', segmented) #remove &amp;  &gt;  ...\n",
    "    segmented = re.sub(r'[\\U00010000-\\U0010ffff]', '', segmented) #remove some emojis\n",
    "    segmented = segmented.lower()\n",
    "    segmented = re.sub(r'rt', '', segmented) #remove retweets\n",
    "    segmented = re.sub(r'([. , ! ? : ; # @ & - ‚Ç¨ $]+)', r' \\1 ', segmented) # replace \n",
    "    segmented = re.sub(r\"(‚Äôt)\", r\" \\1\", segmented) # clitics n‚Äôt\n",
    "    segmented = re.sub(r\"('t)\", r\" \\1\", segmented) # clitics n't\n",
    "    segmented = re.sub(r\"(‚Äôs)\", r\" \\1\", segmented) # clitics ‚Äôs\n",
    "    segmented = re.sub(r\"('s)\", r\" \\1\", segmented) # clitics 's\n",
    "    segmented = re.sub(r\"(‚Äôre)\", r\" \\1\", segmented) # clitics ‚Äôre\n",
    "    segmented = re.sub(r\"('re)\", r\" \\1\", segmented) # clitics 're\n",
    "    segmented = re.sub(r\"(‚Äôm)\", r\" \\1\", segmented) # clitics ‚Äôm\n",
    "    segmented = re.sub(r\"('m)\", r\" \\1\", segmented) # clitics 'm\n",
    "    segmented = re.sub(r\"(‚Äôve)\", r\" \\1\", segmented) # clitics ‚Äôve\n",
    "    segmented = re.sub(r\"('ve)\", r\" \\1\", segmented) # clitics ve\n",
    "    segmented = re.sub(r\"(‚Äôd)\", r\" \\1\", segmented) # clitics ‚Äôd\n",
    "    segmented = re.sub(r\"('d)\", r\" \\1\", segmented) # clitics 'd\n",
    "    segmented = re.sub(r\"(‚Äôll)\", r\" \\1\", segmented) # clitics ‚Äôll\n",
    "    segmented = re.sub(r\"('ll)\", r\" \\1\", segmented) # clitics 'll\n",
    "    segmented = re.sub(r'\\s+', ' ',   segmented) # Remove duplicate whitespaces*\n",
    "    \n",
    "    heuristic_seg_docs.append(segmented)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>check out my class in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extending a big thank you to our community pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blueberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad day ‚òπÔ∏è¬ÆÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i 'm chim tho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0                             check out my class in \n",
       "1  extending a big thank you to our community pan...\n",
       "2                                         blueberry \n",
       "3                                       bad day ‚òπÔ∏è¬ÆÔ∏è\n",
       "4                                      i 'm chim tho"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data\n",
    "df = pd.DataFrame({'Tweets':heuristic_seg_docs})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results off the UDPipe and the heuristic segmentation are quite different. The heuristic method works pretty good in English atleast. You have to take into consideration the language specific rules. The links and twitter handles are easy to remove with a few regexes. If the heuristic method gets slang or badly written english it might do some weird segmentations, ex. i'mma -> \" i 'mma \". The heuristic model can target more specific segmentation needs, but also requires a lot of work to do it propperly. I prefer to this example the heuristic method because of the ability to easily remove all the hashtags, twitter handles, links and other trash in the text.\n",
    "\n",
    "Comparing the first tweets shows that the links and hashtags have dissapeared in the heuristic method. Other wise they have pretty similar results.\n",
    "\n",
    "The UDPipe machine learned model works very well. It takes into account clitics and hyphenated compound words.\n",
    "The UDPipe can be trained and work with several languages. It seems to be a very good and fast way of segmenting words if you have a trained classifier. This seems to be the optimal way of segmenting texts if you want to do it fast and well. \n",
    "\n",
    "The both methods seem to have done a good job, but to truly meassure the performance of the two sgementation method you could meassue the amount of words that are correctly segmented. I will use the heurisitc method in the following calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Count a word frequency list \n",
    "\n",
    "**Count a word frequency list (how many times each word appears and how many unique words there are). Which are the most commmon words appearing in the data? What kind of words these are?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word frequency counter\n",
    "\n",
    "#from collections import Counter\n",
    "\n",
    "token_counter = Counter()\n",
    "\n",
    "for doc in heuristic_seg_docs: \n",
    "    tokenized = pipeline.process(doc)\n",
    "    tokens = tokenized.split() # after segmenter, we can do whitespace splitting\n",
    "    token_counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>.</td>\n",
       "      <td>5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>,</td>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>to</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>2940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>and</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>of</td>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>for</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>is</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>:</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>it</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>!</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>this</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>on</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>that</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Count\n",
       "69      .   5929\n",
       "16    the   4345\n",
       "92      ,   3714\n",
       "10     to   3445\n",
       "6       a   2940\n",
       "23      i   2871\n",
       "78    and   2705\n",
       "9     you   2663\n",
       "63     of   2069\n",
       "4      in   1945\n",
       "37    for   1858\n",
       "286    is   1765\n",
       "33      :   1595\n",
       "88     it   1531\n",
       "18      !   1418\n",
       "41      -   1407\n",
       "74   this   1248\n",
       "138    on   1217\n",
       "210  that   1158\n",
       "2      my   1119"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data\n",
    "print(\"Vocabulary size:\", len(token_counter))\n",
    "df = pd.DataFrame.from_dict(token_counter, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Word', 0:'Count'})\n",
    "df.sort_values('Count', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vocabulary size of the segmented documents is 17187. \n",
    "Before cleaning the tokens, the most common words seem to be punctuation charachters and so called stop words. \n",
    "\n",
    "Let's clean the data a bit and then take a closer look. Let's remove some of the stop words and punctuation characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words and punctuation characters\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords') # download the stopwords dataset\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "filtered_tokens = []\n",
    "punctuation_chars = '. .. , : ( ) ! !! ? ?? \" = & - ; ... \\\\ \" ‚Äù [ ] # @ ‚Äú / * % ‚Ç¨ $ '.split() # list of punctuation symbols to ignore\n",
    "for word, count in token_counter.most_common():\n",
    "    if word.lower() in stopwords.words(\"english\") or word in punctuation_chars:\n",
    "        continue\n",
    "    filtered_tokens.append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17014\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'s</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christmas</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'t</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‚Äôt</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>‚Äô</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>love</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>year</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>day</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>good</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>today</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Count\n",
       "0          's    929\n",
       "1          ‚Äôs    642\n",
       "2   christmas    579\n",
       "3          't    569\n",
       "4        like    532\n",
       "5          ‚Äôt    474\n",
       "6         one    456\n",
       "7           ‚Äô    447\n",
       "8        love    438\n",
       "9      people    396\n",
       "10        new    379\n",
       "11       year    345\n",
       "12        get    344\n",
       "13        day    339\n",
       "14          '    339\n",
       "15       2017    304\n",
       "16       good    297\n",
       "17       time    296\n",
       "18      today    262\n",
       "19       2018    259"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data\n",
    "print(\"Vocabulary size:\", len(filtered_tokens))\n",
    "df = pd.DataFrame(filtered_tokens)\n",
    "df = df.rename(columns={0:'Word', 1:'Count'})\n",
    "df.sort_values('Count', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing stop words, some punctuation the vocabulary size changed to 17014 which is only 173 tokens removed.\n",
    "\n",
    "The vocabulary still has some emoticons/emojis/dingbats/symbols etc. We will ignore those for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO unique words and how many times each word appears\n",
    "\n",
    "The some of most common words are the: \n",
    "* 's clitic \n",
    "* Christmas\n",
    "* 't clitic\n",
    "* like\n",
    "* one\n",
    "* love\n",
    "* people\n",
    "* new\n",
    "* year\n",
    "* get\n",
    "* day \n",
    "* 2017\n",
    "* good\n",
    "* time\n",
    "* today\n",
    "\n",
    "If we only look at the words, not numbers or clitics then we have:\n",
    "* Christmas\n",
    "* like\n",
    "* one\n",
    "* love\n",
    "* people\n",
    "* new\n",
    "* year\n",
    "* get\n",
    "* day \n",
    "* good\n",
    "* time\n",
    "* today\n",
    "\n",
    "**The words are mostly Nouns** with a few verbs and adjectives in the mix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'s</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christmas</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'t</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‚Äôt</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>‚Äô</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>love</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>year</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>day</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>good</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>today</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>see</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>know</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>need</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>got</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>family</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>life</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>want</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Count\n",
       "0          's    929\n",
       "1          ‚Äôs    642\n",
       "2   christmas    579\n",
       "3          't    569\n",
       "4        like    532\n",
       "5          ‚Äôt    474\n",
       "6         one    456\n",
       "7           ‚Äô    447\n",
       "8        love    438\n",
       "9      people    396\n",
       "10        new    379\n",
       "11       year    345\n",
       "12        get    344\n",
       "13        day    339\n",
       "14          '    339\n",
       "15       2017    304\n",
       "16       good    297\n",
       "17       time    296\n",
       "18      today    262\n",
       "19       2018    259\n",
       "20        see    251\n",
       "21       know    244\n",
       "22          1    235\n",
       "23          u    234\n",
       "24       need    232\n",
       "25        got    229\n",
       "26     family    228\n",
       "27          2    224\n",
       "28       life    224\n",
       "29       want    222"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 30 most common words \n",
    "df.sort_values('Count', ascending=False)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate **idf** weight for each word appearing in the data \n",
    "**Calculate idf weight for each word appearing in the data (one tweet = one document), and print top 20 words with lowest and highest idf values. Why tf not really matter when processing tweets?**\n",
    "\n",
    "Let's start by creating the TF and IDF functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF for all\n",
    "wordDictionary = dict(filtered_tokens)\n",
    "wordDictionary.update({key : 0 for key in wordDictionary.keys()})\n",
    "\n",
    "tfDocuments = {}\n",
    "key = 0\n",
    "\n",
    "for doc in heuristic_seg_docs:\n",
    "    \n",
    "    docWordDictionary = {}\n",
    "\n",
    "    bagOfWords = doc.split(\" \")\n",
    "    for word in bagOfWords:\n",
    "        if word in docWordDictionary:\n",
    "            docWordDictionary[word] += 1\n",
    "        else:\n",
    "            docWordDictionary[word] = 1\n",
    "\n",
    "    tfDocuments[key] = docWordDictionary\n",
    "    key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateIDF(documents):\n",
    "    import math\n",
    "    n = len(documents)\n",
    "    \n",
    "    idf = dict(filtered_tokens)\n",
    "    idf.update({key : 0 for key in idf.keys()})\n",
    "    \n",
    "    for key, value in documents.items():\n",
    "        for word in value:\n",
    "            try:\n",
    "                idf[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        #for word in doc:\n",
    "         #   idf[word] += 1\n",
    "\n",
    "    for word, count in idf.items():\n",
    "        try:\n",
    "            idf[word] = math.log(n/float(count))\n",
    "        except:\n",
    "            pass\n",
    "        #print(float(count))\n",
    "        \n",
    "    \n",
    "    return idf\n",
    "\n",
    "\n",
    "idfValues = calculateIDF(tfDocuments)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>kafirs</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>727</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>militaryoffice</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11107</th>\n",
       "      <td>photocard</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>ouch</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109</th>\n",
       "      <td>richmond</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11110</th>\n",
       "      <td>bumble</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11111</th>\n",
       "      <td>speedruns</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11112</th>\n",
       "      <td>opengl</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11113</th>\n",
       "      <td>tutorials</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>sdl</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11115</th>\n",
       "      <td>vampires</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11116</th>\n",
       "      <td>o-man</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11119</th>\n",
       "      <td>leaks</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>pnc</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>t'was</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>ambitions</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>intense</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>advance</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>jtbc</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word      idf\n",
       "8507           kafirs  9.21034\n",
       "11122             727  9.21034\n",
       "11106  militaryoffice  9.21034\n",
       "11107       photocard  9.21034\n",
       "11108            ouch  9.21034\n",
       "11109        richmond  9.21034\n",
       "11110          bumble  9.21034\n",
       "11111       speedruns  9.21034\n",
       "11112          opengl  9.21034\n",
       "11113       tutorials  9.21034\n",
       "11114             sdl  9.21034\n",
       "11115        vampires  9.21034\n",
       "11116           o-man  9.21034\n",
       "11119           leaks  9.21034\n",
       "11121             pnc  9.21034\n",
       "11123           t'was  9.21034\n",
       "11104       ambitions  9.21034\n",
       "11124         intense  9.21034\n",
       "11125         advance  9.21034\n",
       "11126            jtbc  9.21034"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(idfValues, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Word', 0:'idf'})\n",
    "df.sort_values('idf', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>xxxtentacion</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15606</th>\n",
       "      <td>/it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8644</th>\n",
       "      <td>adley</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15621</th>\n",
       "      <td>-open</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>29-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>nu</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8619</th>\n",
       "      <td>crippled</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15641</th>\n",
       "      <td>+1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15642</th>\n",
       "      <td>sathi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>-twe</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15657</th>\n",
       "      <td>971565841893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604</th>\n",
       "      <td>quotas</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>1919</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15679</th>\n",
       "      <td>acash</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>autonomous</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>pictured</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>zhou</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>luck‚ú®</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>unite</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8564</th>\n",
       "      <td>nenza</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  idf\n",
       "12279  xxxtentacion  0.0\n",
       "15606           /it  0.0\n",
       "8644          adley  0.0\n",
       "15621         -open  0.0\n",
       "8626          29-12  0.0\n",
       "15634            nu  0.0\n",
       "8619       crippled  0.0\n",
       "15641            +1  0.0\n",
       "15642         sathi  0.0\n",
       "15643          -twe  0.0\n",
       "15657  971565841893  0.0\n",
       "15604        quotas  0.0\n",
       "15664          1919  0.0\n",
       "15679         acash  0.0\n",
       "15683    autonomous  0.0\n",
       "15684      pictured  0.0\n",
       "8571           zhou  0.0\n",
       "15685         luck‚ú®  0.0\n",
       "15689         unite  0.0\n",
       "8564          nenza  0.0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(idfValues, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Word', 0:'idf'})\n",
    "df.sort_values('idf', ascending=True)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateIDF(documents):\n",
    "    import math\n",
    "    n = len(documents)\n",
    "    \n",
    "    idf = {}\n",
    "    \n",
    "    for key, value in documents.items():\n",
    "        for word in value:\n",
    "            if word in idf:\n",
    "                idf[word] += 1\n",
    "            else:\n",
    "                idf[word] = 1\n",
    "\n",
    "\n",
    "    for word, count in idf.items():\n",
    "            idf[word] = math.log(n/float(count))\n",
    "\n",
    "    \n",
    "    return idf\n",
    "\n",
    "\n",
    "idfValues = calculateIDF(tfDocuments)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19112</th>\n",
       "      <td>fridge</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>it‚Äòs</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>tan</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>bulldog</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9541</th>\n",
       "      <td>murali</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>sharmawe</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9543</th>\n",
       "      <td>costar</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>priory</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9547</th>\n",
       "      <td>endure</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>maknaes</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>young\"</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>kmelo</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>obscene)</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>winslet</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9554</th>\n",
       "      <td>self-obsessed</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>hedonistic</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15484</th>\n",
       "      <td>linick</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>divisive</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>trillion</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>\"russia</td>\n",
       "      <td>9.21034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word      idf\n",
       "19112         fridge  9.21034\n",
       "9551            it‚Äòs  9.21034\n",
       "9539             tan  9.21034\n",
       "9540         bulldog  9.21034\n",
       "9541          murali  9.21034\n",
       "9542        sharmawe  9.21034\n",
       "9543          costar  9.21034\n",
       "9544          priory  9.21034\n",
       "9547          endure  9.21034\n",
       "9548         maknaes  9.21034\n",
       "9549          young\"  9.21034\n",
       "9550           kmelo  9.21034\n",
       "9552        obscene)  9.21034\n",
       "9569         winslet  9.21034\n",
       "9554   self-obsessed  9.21034\n",
       "9555      hedonistic  9.21034\n",
       "15484         linick  9.21034\n",
       "9558        divisive  9.21034\n",
       "9560        trillion  9.21034\n",
       "9562         \"russia  9.21034"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(idfValues, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Word', 0:'idf'})\n",
    "df.sort_values('idf', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>0.143870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>.</td>\n",
       "      <td>1.090644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>1.241329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>to</td>\n",
       "      <td>1.363359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>1.470981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>,</td>\n",
       "      <td>1.474907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>and</td>\n",
       "      <td>1.563032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i</td>\n",
       "      <td>1.639897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>you</td>\n",
       "      <td>1.691733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>of</td>\n",
       "      <td>1.799993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>for</td>\n",
       "      <td>1.810942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>1.834458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>is</td>\n",
       "      <td>1.906497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>it</td>\n",
       "      <td>2.107018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>!</td>\n",
       "      <td>2.177716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>this</td>\n",
       "      <td>2.178599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>on</td>\n",
       "      <td>2.216407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>:</td>\n",
       "      <td>2.254748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>that</td>\n",
       "      <td>2.318714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my</td>\n",
       "      <td>2.381628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word       idf\n",
       "5          0.143870\n",
       "66      .  1.090644\n",
       "17    the  1.241329\n",
       "11     to  1.363359\n",
       "7       a  1.470981\n",
       "89      ,  1.474907\n",
       "75    and  1.563032\n",
       "24      i  1.639897\n",
       "10    you  1.691733\n",
       "60     of  1.799993\n",
       "38    for  1.810942\n",
       "4      in  1.834458\n",
       "281    is  1.906497\n",
       "85     it  2.107018\n",
       "19      !  2.177716\n",
       "71   this  2.178599\n",
       "134    on  2.216407\n",
       "34      :  2.254748\n",
       "204  that  2.318714\n",
       "2      my  2.381628"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(idfValues, orient='index').reset_index()\n",
    "df = df.rename(columns={'index':'Word', 0:'idf'})\n",
    "df.sort_values('idf', ascending=True)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IDF calculation method\n",
    "def calculateIDF(documents):\n",
    "    import math\n",
    "    n = len(documents)\n",
    "    \n",
    "    idf = dict(filtered_tokens)\n",
    "    idf.update({key : 0 for key in idf.keys()})\n",
    "    \n",
    "    for doc in documents:\n",
    "        \n",
    "        uniqueWords = dict.fromkeys(doc.split(\" \"),0)\n",
    "        \n",
    "        for word in uniqueWords:\n",
    "            try:\n",
    "                idf[word] += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    for word, count in idf.items():\n",
    "        idf[word] = math.log(n/float(count))\n",
    "        print(float(count))\n",
    "        \n",
    "    \n",
    "    return idf\n",
    "\n",
    "\n",
    "idfValues = calculateIDF(heuristic_seg_docs)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
