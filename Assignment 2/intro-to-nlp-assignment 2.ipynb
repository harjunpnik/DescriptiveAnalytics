{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP: Assignment 2 \n",
    "\n",
    "## Assignment on Text Classification and Sequence Labeling\n",
    "\n",
    "### Description of Assignment 2\n",
    "\n",
    "This assignment relates to the Text classification and Sequence labeling themes of the introduction to NLP (courses Deskriptiv analytik / Machine learning for descriptive problems), and will focus on gaining some practical, hands-on experience in building and training simple models for these tasks.\n",
    "\n",
    "The assignment is handed in as a Jupyternotebook (or a PDF render thereof) containing the code used to solve the problem, output presenting the results, and, most importantly, notes that present the students' conclusions and answer questions posed in the assignment.\n",
    "\n",
    "**Assignment steps/Questions:**\n",
    "\n",
    "1. Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?\n",
    "\n",
    "2. Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "3. In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.\n",
    "\n",
    "4. If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?\n",
    "\n",
    "5. **BONUS** On the address universaldependencies.org, you will find datasets for a bunch of languages. These come in an easy-to-parse, well-documented format. Pick one language that interests you, and one treebank for that language, and try to builda POS tagger for this language. You can use the 4th column “UPOS” [https://universaldependencies.org/format.html](https://universaldependencies.org/format.html) Report on your findings. If you have extra time, try to experiment with various features and see if you can make your accuracy go up. You can check here [https://universaldependencies.org/conll18/results-upos.html](https://universaldependencies.org/conll18/results-upos.html) what the state of the art roughly is for your selected language and treebank. Did you come close?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: neg\n",
      "text: the single worst film i've ever seen in a theater. i saw this film at the austin film festival in 2004, and it blew my mind that this film was accepted to a festival. it was an interesting premise, and seemed like it could go somewhere, but just fell apart every time it tried to do anything. first of all, if you're going to do a musical, find someone with musical talent. the music consisted of cheesy piano playing that sounded like they were playing it on a stereo in the room they were filming. the lyrics were terribly written, and when they weren't obvious rhymes, they were groan-inducing rhymes that showed how far they were stretching to try to make this movie work. and you'd think you'd find people who could sing when making a musical, right? not in this case. luckily they were half talking/half singing in rhyme most of the time, but when they did sing it made me cringe. especially when they attempted to sing in harmony. and that just addresses the music. some of the acting was pretty good, but a lot of the dialog was terrible, as well as most of the scenes. they obviously didn't have enough coverage on the scenes, or they just had a bad editor, because they consistently jumped the line and used terrible choices while cutting the film. at least the director was willing to admit that no one wanted the script until they added the hook of making it a musical. i hope the investors make sure someone can write music before making the same mistake again.\n"
     ]
    }
   ],
   "source": [
    "with open(\"imdb_train.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "random.seed(10) # Seed to replicate same scenario for development\n",
    "random.shuffle(data) # Shuffle data \n",
    "\n",
    "# Preview of data\n",
    "print(\"class label:\", data[0][\"class\"])\n",
    "print(\"text:\", data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate texts and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of texts: 25000\n",
      "Amount of labels 25000\n",
      "\n",
      "neg the single worst film i've ever seen in a theater....\n",
      "pos I think the reason for all the opinionated diarrhe...\n",
      "neg This movie is horrible! It rivals \\Ishtar\\\" in the...\n",
      "neg This may not be the worst comedy of all time, but ...\n",
      "pos I found this film to funny from the start. John Wa...\n",
      "pos The problem is that the movie rode in on the coatt...\n",
      "neg I was so looking forward to seeing this when it wa...\n",
      "neg I actually saw this movie in the theater back in i...\n",
      "neg blows my mind how this movie got made. i watched i...\n",
      "neg Amateurish in the extreme. Camera work especially ...\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts and labels into separate lists\n",
    "texts=[d[\"text\"] for d in data]\n",
    "labels=[d[\"class\"] for d in data]\n",
    "print(\"Amount of texts:\", len(texts))\n",
    "print(\"Amount of labels\", len(labels))\n",
    "print()\n",
    "for label, text in list(zip(labels, texts))[:10]:\n",
    "    print(label, text[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test sklearn’s TfidfVectorizer\n",
    "\n",
    "**Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(texts, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method for easier showing results in changes of n-grams and C-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(ngramRange, maxFeatures, cValue, vectorizerType):\n",
    "    # Change vectorizer type based on variable\n",
    "    if(vectorizerType == \"Count\"):\n",
    "        vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    if(vectorizerType == \"Idf\"):\n",
    "        vectorizer = TfidfVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    \n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    print(\"Vectorizer type={0}, C={1}, n-gram={2}\".format(vectorizerType, cValue, ngramRange))\n",
    "    print(\"DEV\", classifier.score(feature_matrix_dev, dev_labels))\n",
    "    print(\"TRAIN\", classifier.score(feature_matrix_train, train_labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.873\n",
      "TRAIN 0.89445\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8902\n",
      "TRAIN 0.95705\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8784\n",
      "TRAIN 0.99605\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.864\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Idf, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.8396\n",
      "TRAIN 0.84415\n",
      "\n",
      "Vectorizer type=Idf, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8568\n",
      "TRAIN 0.8668\n",
      "\n",
      "Vectorizer type=Idf, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8892\n",
      "TRAIN 0.92155\n",
      "\n",
      "Vectorizer type=Idf, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8972\n",
      "TRAIN 0.9838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Idf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing TfidfVectorizer and CountVectorizer when changing C value \n",
    "\n",
    "First thing I noticed was that the classification results where very similar. The Count Vectorizers dev and train results are higher on a lower C value like 0.0005. When the C value is increased the Count Vectorizers Train rises to 0.95 very fast and even to 1.0 meanwhile the dev results go up to 0.88 and down to 0.86 when C value is 0.5. The optimal C value for the count vectorizer is probably around 0.005 where the data has not been overfitted to the train data. \n",
    "\n",
    "As mentioned above the Count vectorizers results where higher on a lower C value. The Tfidf Vectorizer with a C value of 0.0005 has results around 0.84 on dev and train. When the C Value is increased, both the dev and train results increase steadily. Only after a C value as high as 0.5 is where the dev and train start to separate eachother. I'd say that the optimal C value for the Tfidf Vectorizer is around 0.05 because of diminishing returns on the dev result. This method seems to do a better job with not overfitting with the data. \n",
    "\n",
    "The Tfidf Vectorizer when it is run with an optimal C value has better dev results than Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test different lengths of n-grams in the CountVectorizer on the IMDB data\n",
    "\n",
    "**Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?**\n",
    "\n",
    "\n",
    "Lets start by looking att the results of different n-grams and try to find their optimal C values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.873\n",
      "TRAIN 0.89445\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8902\n",
      "TRAIN 0.95705\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8784\n",
      "TRAIN 0.99605\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.864\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 2)\n",
      "DEV 0.8878\n",
      "TRAIN 0.93365\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 2)\n",
      "DEV 0.9016\n",
      "TRAIN 0.9941\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.896\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.5, n-gram=(1, 2)\n",
      "DEV 0.894\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 3)\n",
      "DEV 0.8906\n",
      "TRAIN 0.9398\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 3)\n",
      "DEV 0.9026\n",
      "TRAIN 0.99595\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.8974\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.5, n-gram=(1, 3)\n",
      "DEV 0.8934\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(2, 3)\n",
      "DEV 0.8606\n",
      "TRAIN 0.92105\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(2, 3)\n",
      "DEV 0.8816\n",
      "TRAIN 0.99445\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.8678\n",
      "TRAIN 1.0\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(2, 3)\n",
      "DEV 0.8618\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of different n-grams\n",
    "\n",
    "When the n-grams are increased the C Value does not need to be that big. The Classifiers results are almost optimal at a value of 0.0005. The n-grams become very fast overfitted to the  train data if the C value is too high. I'd say the most optimal was an n-gram range of (1,2) and the C value as 0.005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "Lets create a mehtod for showing the most significant features. After that we can look at the n-gram ranges of (1,2) and (2,3) since (1,1) will only consist of 1 lenght features.\n",
    "\n",
    "### Create method for showing significant Features based on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSignificantFeatures(maxFeatures, ngramRange, cValue):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    index2feature={}\n",
    "    for feature,idx in vectorizer.vocabulary_.items():\n",
    "        assert idx not in index2feature #This really should hold\n",
    "        index2feature[idx]=feature\n",
    "    \n",
    "    indices=numpy.argsort(classifier.coef_[0])\n",
    "    print(indices)\n",
    "    for idx in indices[:30]:\n",
    "        print(index2feature[idx])\n",
    "    print(\"-------------------------------\")\n",
    "    for idx in indices[::-1][:30]:\n",
    "        print(index2feature[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (1,2)\n",
      "[ 9727 98461 13456 ... 34272 63854 27397]\n",
      "awful\n",
      "worst\n",
      "boring\n",
      "waste\n",
      "disappointing\n",
      "disappointment\n",
      "dull\n",
      "poorly\n",
      "the worst\n",
      "bad\n",
      "poor\n",
      "horrible\n",
      "terrible\n",
      "unfortunately\n",
      "not worth\n",
      "badly\n",
      "worse\n",
      "lame\n",
      "annoying\n",
      "lacks\n",
      "at best\n",
      "save\n",
      "stupid\n",
      "laughable\n",
      "waste of\n",
      "oh\n",
      "avoid\n",
      "mess\n",
      "not even\n",
      "basically\n",
      "-------------------------------\n",
      "excellent\n",
      "perfect\n",
      "great\n",
      "wonderful\n",
      "enjoyable\n",
      "superb\n",
      "amazing\n",
      "incredible\n",
      "better than\n",
      "enjoyed\n",
      "today\n",
      "pretty good\n",
      "fun\n",
      "must see\n",
      "brilliant\n",
      "10 10\n",
      "perfectly\n",
      "simple\n",
      "realistic\n",
      "well worth\n",
      "definitely worth\n",
      "beautiful\n",
      "definitely\n",
      "refreshing\n",
      "highly\n",
      "gem\n",
      "rare\n",
      "job\n",
      "wonderfully\n",
      "fantastic\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (1,2)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (2,3)\n",
      "[81494 93036  9743 ... 94089 52062 39579]\n",
      "the worst\n",
      "waste of\n",
      "at best\n",
      "not even\n",
      "of the worst\n",
      "not worth\n",
      "than this\n",
      "unless you\n",
      "bad movie\n",
      "at all\n",
      "bad acting\n",
      "is awful\n",
      "so bad\n",
      "worse than\n",
      "is bad\n",
      "worst movie\n",
      "boring and\n",
      "fails to\n",
      "is terrible\n",
      "might have\n",
      "attempt to\n",
      "bad and\n",
      "even worse\n",
      "looks like\n",
      "way too\n",
      "not good\n",
      "not very\n",
      "the original\n",
      "is nothing\n",
      "much better\n",
      "-------------------------------\n",
      "is great\n",
      "must see\n",
      "well worth\n",
      "highly recommended\n",
      "the best\n",
      "an excellent\n",
      "10 10\n",
      "is excellent\n",
      "my favorite\n",
      "enjoyed it\n",
      "was great\n",
      "loved it\n",
      "definitely worth\n",
      "highly recommend\n",
      "loved this\n",
      "great movie\n",
      "very good\n",
      "love this\n",
      "great job\n",
      "enjoyed this\n",
      "very well\n",
      "great film\n",
      "on dvd\n",
      "is perfect\n",
      "is beautiful\n",
      "fun and\n",
      "watch it\n",
      "was excellent\n",
      "of the best\n",
      "love it\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (2,3)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most significant n-grams\n",
    "\n",
    "It seems to be that, the longer the featue, the more unique and more rare it is. If we look at the n-gram range of (1,2), then the most significant features have some words that are 2 words long. The majority of the features are still of one length. \n",
    "\n",
    "If we look at the n-gram range (2,3), then this proves also our point. There are some features that consist of 3 words, but most of the features are 2 words. The most common 3 words consists of the words \"of the worst/best\". \n",
    "\n",
    "It is rare that longer sentences would occur several times in normal text or literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train an SVM classifier for language recognition\n",
    "\n",
    "**In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create methods for reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openTextFile(lang, section):\n",
    "    path = \"./language-identification/{0}_{1}.txt\".format(lang, section)\n",
    "    textList = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            obj = {'lang': lang,\n",
    "               'text': line.strip()\n",
    "            }\n",
    "            textList.append(obj)\n",
    "            \n",
    "    return textList\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateLabelText(data):\n",
    "    texts=[d[\"text\"] for d in data]\n",
    "    labels=[d[\"lang\"] for d in data]\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLangFiles(languages):\n",
    "    trainData = []\n",
    "    develData = []\n",
    "    testData = []\n",
    "    \n",
    "    for lang in languages:\n",
    "        trainData.extend(openTextFile(lang, 'train'))\n",
    "        develData.extend(openTextFile(lang, 'devel'))\n",
    "        testData.extend(openTextFile(lang, 'test'))\n",
    "\n",
    "    # Shuffle Data\n",
    "    random.seed(10) # Seed to replicate same scenario for development\n",
    "    random.shuffle(trainData) # Shuffle data \n",
    "    random.shuffle(develData) # Shuffle data \n",
    "    random.shuffle(testData) # Shuffle data \n",
    "    \n",
    "    # Separate labels from text\n",
    "    trainTexts, trainLabels = separateLabelText(trainData)\n",
    "    develTexts, develLabels = separateLabelText(develData)\n",
    "    testTexts, testLabels = separateLabelText(testData)\n",
    "\n",
    "        \n",
    "    return trainTexts, trainLabels, develTexts, develLabels, testTexts, testLabels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature matrix and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'et', 'fi', 'pt']\n",
    "# Read in the texts and labels\n",
    "lang_text_train, lang_label_train, lang_text_dev, lang_label_dev, lang_text_test, lang_label_test = loadLangFiles(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n"
     ]
    }
   ],
   "source": [
    "lang_vectorizer = TfidfVectorizer(max_features = 100000, binary=True, ngram_range = (1,1))\n",
    "lang_feature_matrix_train = lang_vectorizer.fit_transform(lang_text_train)\n",
    "lang_feature_matrix_dev = lang_vectorizer.transform(lang_text_dev)\n",
    "lang_feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "\n",
    "lang_classifier = sklearn.svm.LinearSVC(C = 0.05, verbose = 0)\n",
    "lang_classifier.fit(lang_feature_matrix_train, lang_label_train)\n",
    "\n",
    "print(\"DEV\", lang_classifier.score(lang_feature_matrix_dev, lang_label_dev))\n",
    "print(\"TEST\", lang_classifier.score(lang_feature_matrix_test, lang_label_test))\n",
    "print(\"TRAIN\", lang_classifier.score(lang_feature_matrix_train, lang_label_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLang(text, vectorizer, classifier):\n",
    "    data = vectorizer.transform([text])\n",
    "    \n",
    "    prediction = classifier.predict(data)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n",
      "['es']\n",
      "['et']\n",
      "['fi']\n",
      "['pt']\n"
     ]
    }
   ],
   "source": [
    "predictLang(\"Today is a nice day.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Estas obras son realizadas con libros, álbumes de música o periódicos como soporte.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Publik teeb nii mitu korda ja on juba üles köetud.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Tänään on mahti päivä mennä kävelylle.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Conseguir um bom exclusivo pode significar a entrada de milhões de dólares em publicidade.\", lang_vectorizer, lang_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Toy around with features, especially the ngram_range and analyzer parameters\n",
    "\n",
    "**If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method for easier comparisons of changes in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLangClassifier(ngramRange, maxFeatures, cValue, analyzerParam):\n",
    "    lang_vectorizer = TfidfVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange, analyzer = analyzerParam)\n",
    "    lang_feature_matrix_train = lang_vectorizer.fit_transform(lang_text_train)\n",
    "    lang_feature_matrix_dev = lang_vectorizer.transform(lang_text_dev)\n",
    "    lang_feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "\n",
    "    lang_classifier = sklearn.svm.LinearSVC(C = cValue, verbose = 0)\n",
    "    lang_classifier.fit(lang_feature_matrix_train, lang_label_train)\n",
    "\n",
    "    print(\"analyzer={0}, C={1}, n-gram={2}\".format(analyzerParam, cValue, ngramRange))\n",
    "    print(\"DEV\", lang_classifier.score(lang_feature_matrix_dev, lang_label_dev))\n",
    "    print(\"TEST\", lang_classifier.score(lang_feature_matrix_test, lang_label_test))\n",
    "    print(\"TRAIN\", lang_classifier.score(lang_feature_matrix_train, lang_label_train))\n",
    "    print()\n",
    "    \n",
    "    return lang_vectorizer, lang_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer = \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=word, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.9366\n",
      "TEST 0.9406\n",
      "TRAIN 0.9968\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.937\n",
      "TEST 0.9392\n",
      "TRAIN 0.993\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(2, 2)\n",
      "DEV 0.759\n",
      "TEST 0.7616\n",
      "TRAIN 0.9842\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.7484\n",
      "TEST 0.7522\n",
      "TRAIN 0.9796\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(3, 3)\n",
      "DEV 0.398\n",
      "TEST 0.4048\n",
      "TRAIN 0.9734\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (3,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer = \"char\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=char, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8896\n",
      "TEST 0.8864\n",
      "TRAIN 0.8978\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.9736\n",
      "TEST 0.9762\n",
      "TRAIN 0.9832\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.979\n",
      "TEST 0.9826\n",
      "TRAIN 0.9922\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(2, 2)\n",
      "DEV 0.972\n",
      "TEST 0.9756\n",
      "TRAIN 0.9822\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.979\n",
      "TEST 0.9826\n",
      "TRAIN 0.9928\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(3, 3)\n",
      "DEV 0.9782\n",
      "TEST 0.9832\n",
      "TRAIN 0.994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (3,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of classification \n",
    "\n",
    "When increasing the word feature count it should not have an big effect on the result. To me it is very understandable that the uniqueness of the 2 word or longer features would not have an effect on the classification. I still am curious why when using the word analyzer, that the classification would fail. When comparing Finnish to Estonian, the languages might look very similar, but there are major differences. My bet is that when the lenght of a document is short, the classifier might find it hard to find the correct language because the same words might appear in other languages.\n",
    "\n",
    "When using characters as features the results are quite different. The singel character feature works quite well because of languages having their own letters. \n",
    "When the feature lenght is increased, the accuracy is immensely increased. Every language has its own gramar rules. This will make some letter frequencies more common. \n",
    "\n",
    "To get the best accuracy, one could combine the score from words and from the characters and take the average value of that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find misclassified documents\n",
    "\n",
    "I want to find out why the classifier fails **when using words as features**. Lets look at the confusion matrix and some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=word, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect, classifer  = createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "en es et fi pt\n",
      "[[906   3   4  78   9]\n",
      " [  1 981   1   8   9]\n",
      " [  2   3 911  84   0]\n",
      " [  3   3  34 959   1]\n",
      " [  2   6   1  52 939]]\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "predictions_test=classifer.predict(feature_matrix_test)\n",
    "print(\"confusion matrix\")\n",
    "print('en', 'es', 'et', 'fi', 'pt')\n",
    "print(sklearn.metrics.confusion_matrix(lang_label_test,predictions_test, labels=['en', 'es', 'et', 'fi', 'pt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix goes from EN -> ES -> ET -> FI -> PT.\n",
    "\n",
    "Most of the missclassifications seem to be around Finnish. The model might have been overfitted for finnish when comparing english text. Meanwhile the confusion in classification of Estonian and Finnish texts are understandable. Gramatically they are very similar. Although, the classifier seems to classify more on the Finnish side than estonian. Even some Portugese text have been classified as Finnish. I strongly believe the documents to contain words similar to Finnish language and be short texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the missclassified documents\n",
    "\n",
    "Lets create a class that contains the info needed for our predictions and save them to a list. After that we can look more closely what might have gone wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangPred:\n",
    "    \n",
    "    def __init__(self, lang, pred, text):\n",
    "        self.lang = lang\n",
    "        self.pred = pred\n",
    "        self.text = text\n",
    "    \n",
    "    def showPred(self):\n",
    "        print(\"Lang= {0}\".format(self.lang)) \n",
    "        print(\"Prediction= {0}\".format(self.pred)) \n",
    "        print(\"Text= {0}\".format(self.text))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassifed = []\n",
    "\n",
    "incre = 0 \n",
    "for text in lang_text_test:\n",
    "    data = vect.transform([text])\n",
    "    prediction = classifer.predict(data)\n",
    "    \n",
    "    if prediction != lang_label_test[incre]:\n",
    "        missclassifed.append(LangPred(lang_label_test[incre], prediction, text))\n",
    "        \n",
    "    incre += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets analyse some misscalssifed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang= en\n",
      "Prediction= ['fi']\n",
      "Text= 09/16/99 09:48 PM\n",
      "\n",
      "Lang= et\n",
      "Prediction= ['en']\n",
      "Text= \" More\"!\n",
      "\n",
      "Lang= pt\n",
      "Prediction= ['fi']\n",
      "Text= Harmonização« inoportuna»\n",
      "\n",
      "Lang= en\n",
      "Prediction= ['fi']\n",
      "Text= Fascinating.\n",
      "\n",
      "Lang= pt\n",
      "Prediction= ['fi']\n",
      "Text= E o Brasil?\n",
      "\n",
      "Lang= et\n",
      "Prediction= ['fi']\n",
      "Text= “ Jansu on mõnus ja heatahtlik mutrike, huvitav nähtus tantsumaailmas.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missclassifed[0].showPred()\n",
    "missclassifed[5].showPred()\n",
    "missclassifed[10].showPred()\n",
    "missclassifed[15].showPred()\n",
    "missclassifed[20].showPred()\n",
    "missclassifed[21].showPred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting a few of the missclassifed documents, we can se that my theory is quite on point. The texts are mostly short and can easily be missclassfied. The first one contains only numbers and should probably be parsed out of the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BONUS:  Pick one language that interests you, and one treebank for that language, and try to builda POS tagger for this language.\n",
    "\n",
    "**BONUS On the address universaldependencies.org, you will find datasets for a bunch of languages. These come in an easy-to-parse, well-documented format. Pick one language that interests you, and one treebank for that language, and try to builda POS tagger for this language. You can use the 4th column “UPOS” [https://universaldependencies.org/format.html](https://universaldependencies.org/format.html) Report on your findings. If you have extra time, try to experiment with various features and see if you can make your accuracy go up. You can check here [https://universaldependencies.org/conll18/results-upos.html](https://universaldependencies.org/conll18/results-upos.html) what the state of the art roughly is for your selected language and treebank. Did you come close?** \n",
    "\n",
    "Lets start by using the premade POS labeling base from the course and modify it to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three sentences\n",
      "[OneWord(id='1', word='Hvor', lemma='hvor', upos='ADV'), OneWord(id='2', word='kommer', lemma='komme', upos='VERB'), OneWord(id='3', word='julemanden', lemma='julemand', upos='NOUN'), OneWord(id='4', word='fra', lemma='fra', upos='ADP'), OneWord(id='5', word='?', lemma='?', upos='PUNCT')]\n",
      "\n",
      "[OneWord(id='1', word='Flertallet', lemma='flertal', upos='NOUN'), OneWord(id='2', word='lever', lemma='leve', upos='VERB'), OneWord(id='3', word='stadig', lemma='stadig', upos='ADV'), OneWord(id='4', word='under', lemma='under', upos='ADP'), OneWord(id='5', word='plastikstykker', lemma='plastikstykke', upos='NOUN'), OneWord(id='6', word='eller', lemma='eller', upos='CCONJ'), OneWord(id='7', word='tæpper', lemma='tæppe', upos='NOUN'), OneWord(id='8', word=',', lemma=',', upos='PUNCT'), OneWord(id='9', word='som', lemma='som', upos='PRON'), OneWord(id='10', word='de', lemma='de', upos='PRON'), OneWord(id='11', word='har', lemma='have', upos='AUX'), OneWord(id='12', word='spændt', lemma='spænde', upos='VERB'), OneWord(id='13', word='ud', lemma='ud', upos='ADV'), OneWord(id='14', word='over', lemma='over', upos='ADP'), OneWord(id='15', word='nogle', lemma='nogen', upos='DET'), OneWord(id='16', word='stokke', lemma='stok', upos='NOUN'), OneWord(id='17', word='som', lemma='som', upos='ADP'), OneWord(id='18', word='et', lemma='en', upos='DET'), OneWord(id='19', word='improviseret', lemma='improvisere', upos='VERB'), OneWord(id='20', word='telt', lemma='telt', upos='NOUN'), OneWord(id='21', word='.', lemma='.', upos='PUNCT')]\n",
      "\n",
      "[OneWord(id='1', word='Kelds', lemma='Keld', upos='PROPN'), OneWord(id='2', word='oplæg', lemma='oplæg', upos='NOUN'), OneWord(id='3', word='blev', lemma='blive', upos='AUX'), OneWord(id='4', word='fulgt', lemma='følge', upos='VERB'), OneWord(id='5', word='100', lemma='100', upos='NUM'), OneWord(id='6', word='procent', lemma='procent', upos='NOUN'), OneWord(id='7', word=',', lemma=',', upos='PUNCT'), OneWord(id='8', word='\"', lemma='\"', upos='PUNCT'), OneWord(id='9', word='pointerer', lemma='pointere', upos='VERB'), OneWord(id='10', word='Susan', lemma='Susan', upos='PROPN'), OneWord(id='11', word='Mackensie', lemma='Mackensie', upos='PROPN'), OneWord(id='12', word='.', lemma='.', upos='PUNCT')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is how you read a file of this kind\n",
    "# one item per line, empty lines between sequences\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "#Same as tuple but the fields are named for convenience\n",
    "#this says we have four fields\n",
    "OneWord=namedtuple(\"OneWord\",[\"id\",\"word\",\"lemma\",\"upos\"])\n",
    "\n",
    "def read_conll2003(f_name):\n",
    "    \"\"\"Yield complete sentences\"\"\"\n",
    "    current_sentence=[] #This will be a list of (word), which we accumulate for each sentence\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            line=line.strip() #drop whitespace\n",
    "            if line.startswith(\"#\"): #let's not worry about these for the time being\n",
    "                continue\n",
    "            if not line: #sentence break\n",
    "                if current_sentence: #if we gathered a sentence, we should yield it, because a new starts\n",
    "                    yield current_sentence #much like return, but continues past this line once the element has been consumed\n",
    "                    current_sentence=[] #...and start a new one\n",
    "                continue\n",
    "            #if we made it here, we are on a normal line\n",
    "            columns=line.split() #an actual word line\n",
    "            columns=columns[:4]\n",
    "            assert len(columns)==4 #we should have four columns, looking at the data\n",
    "            current_sentence.append(OneWord(*columns))\n",
    "\n",
    "#Now just read the data in\n",
    "sentences_train=list(read_conll2003(\"danish/da_ddt-ud-train.conllu\"))\n",
    "sentences_dev=list(read_conll2003(\"danish/da_ddt-ud-dev.conllu\"))\n",
    "\n",
    "print(\"First three sentences\")\n",
    "for sent in sentences_dev[:3]:\n",
    "    print(sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word_Hvor': 1}, {'word_kommer': 1}, {'word_julemanden': 1}, {'word_fra': 1}, {'word_?': 1}]\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence_features(sent):\n",
    "    #Generate the features for every word\n",
    "    #The result should be a list of same length as the sentence\n",
    "    #Each item is a dictionary of {\"feature name\"->feature value} mappings, holding all features of the word at that position\n",
    "    \n",
    "    sent_features=[] #this will be the result\n",
    "    for one_word in sent:\n",
    "        #We do nothing with the rest of the data\n",
    "        #it just happens to be around\n",
    "        word_features={}\n",
    "        word_features[\"word_\"+one_word.word]=1 #the word itself is a feature\n",
    "        sent_features.append(word_features)\n",
    "    return sent_features\n",
    "\n",
    "print(generate_sentence_features(sentences_dev[0])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(sentences):\n",
    "    all_labels=[] #here we gather labels for all words in all sentences\n",
    "    all_features=[] #here we gather features for all words in all sentences\n",
    "    for sentence in sentences:\n",
    "        sent_features=generate_sentence_features(sentence)\n",
    "        assert len(sent_features)==len(sentence)\n",
    "        #Now we can get, for every position its label and its features\n",
    "        for one_word,features in zip(sentence,sent_features):\n",
    "            all_labels.append(one_word.upos) #label\n",
    "            all_features.append(features)         #and features to go with it\n",
    "    return all_labels, all_features\n",
    "\n",
    "train_labels,train_features=prep_data(sentences_train)\n",
    "dev_labels,dev_features=prep_data(sentences_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer vocab size: 16330\n",
      "Train shape (80378, 16330)\n",
      "Dev shape (10332, 16330)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer=DictVectorizer()\n",
    "vectorizer.fit(train_features)\n",
    "print(\"Vectorizer vocab size:\",len(vectorizer.vocabulary_))\n",
    "\n",
    "feature_vectors_train=vectorizer.transform(train_features)\n",
    "feature_vectors_dev=vectorizer.transform(dev_features)\n",
    "\n",
    "print(\"Train shape\",feature_vectors_train.shape)\n",
    "print(\"Dev shape\",feature_vectors_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=sklearn.svm.LinearSVC(C=0.05,verbose=1)\n",
    "classifier.fit(feature_vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801296941540844"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(feature_vectors_dev,dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this 80 score is pretty good for such a basic classifier. Lets try to use the features of the words to the right and left to determine the POS label more accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (80378, 47795)\n",
      "Dev shape (10332, 47795)\n",
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9124080526519551"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentence_features(sent):\n",
    "    #Generate the features for every word\n",
    "    #The result should be a list of same length as the sentence\n",
    "    #Each item is a dictionary of {\"feature name\"->feature value} mappings, holding all features of the word at that position\n",
    "    \n",
    "    sent_features=[] #this will be the result\n",
    "    for word_idx, one_word in enumerate(sent):\n",
    "        word_features={}\n",
    "        word_features[\"word_\"+one_word.word]=1 #the word itself is a feature\n",
    "        if word_idx!=0:\n",
    "            word_features[\"left_word_\"+sent[word_idx-1].word]=1\n",
    "        if word_idx!=len(sent)-1:\n",
    "            word_features[\"right_word_\"+sent[word_idx+1].word]=1\n",
    "        sent_features.append(word_features)\n",
    "    return sent_features\n",
    "\n",
    "train_labels,train_features=prep_data(sentences_train)\n",
    "dev_labels,dev_features=prep_data(sentences_dev)\n",
    "vectorizer=DictVectorizer()\n",
    "vectorizer.fit(train_features)\n",
    "feature_vectors_train=vectorizer.transform(train_features)\n",
    "feature_vectors_dev=vectorizer.transform(dev_features)\n",
    "\n",
    "print(\"Train shape\",feature_vectors_train.shape)\n",
    "print(\"Dev shape\",feature_vectors_dev.shape)\n",
    "\n",
    "classifier=sklearn.svm.LinearSVC(C=1,verbose=1)\n",
    "classifier.fit(feature_vectors_train, train_labels)\n",
    "classifier.score(feature_vectors_dev,dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 91 score is pretty impressive for just adding that feature generator. For just adding the left and right word features increased the POS taggers score by 10 is amazing. Lets compare this to some of the state of the art POS tagger results are.\n",
    "\n",
    "When comparing the POS taggers from [https://universaldependencies.org/conll18/results-upos.html](https://universaldependencies.org/conll18/results-upos.html) we can easily se that the average of the top taggers for danish is about 97. That is a huge difference in POS tagging compared to the basic one above.\n",
    "\n",
    "If I had more time, I would have probably tried to make a feature changer based on gramar rules. For example that a certain tag can never follow another certain tag, because that would not be gramatically correct. Applying other of these rules would probably fix some of the missclassified features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
