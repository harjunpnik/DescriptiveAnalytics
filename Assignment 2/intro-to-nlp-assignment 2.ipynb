{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP: Assignment 2 \n",
    "\n",
    "## Assignment on Text Classification and Sequence Labeling\n",
    "\n",
    "### Description of Assignment 2\n",
    "\n",
    "This assignment relates to the Text classification and Sequence labeling themes of the introduction to NLP (courses Deskriptiv analytik / Machine learning for descriptive problems), and will focus on gaining some practical, hands-on experience in building and training simple models for these tasks.\n",
    "\n",
    "The assignment is handed in as a Jupyternotebook (or a PDF render thereof) containing the code used to solve the problem, output presenting the results, and, most importantly, notes that present the students' conclusions and answer questions posed in the assignment.\n",
    "\n",
    "**Assignment steps/Questions:**\n",
    "\n",
    "1. Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?\n",
    "\n",
    "2. Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "3. In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.\n",
    "\n",
    "4. If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?\n",
    "\n",
    "5. **BONUS** On the address universaldependencies.org, you will find datasets for a bunch of languages. These come in an easy-to-parse, well-documented format. Pick one language that interests you, and one treebank for that language, and try to builda POS tagger for this language. You can use the 4th column “UPOS” [https://universaldependencies.org/format.html](https://universaldependencies.org/format.html) Report on your findings. If you have extra time, try to experiment with various features and see if you can make your accuracy go up. You can check here [https://universaldependencies.org/conll18/results-upos.html](https://universaldependencies.org/conll18/results-upos.html) what the state of the art roughly is for your selected language and treebank. Did you come close?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: neg\n",
      "text: the single worst film i've ever seen in a theater. i saw this film at the austin film festival in 2004, and it blew my mind that this film was accepted to a festival. it was an interesting premise, and seemed like it could go somewhere, but just fell apart every time it tried to do anything. first of all, if you're going to do a musical, find someone with musical talent. the music consisted of cheesy piano playing that sounded like they were playing it on a stereo in the room they were filming. the lyrics were terribly written, and when they weren't obvious rhymes, they were groan-inducing rhymes that showed how far they were stretching to try to make this movie work. and you'd think you'd find people who could sing when making a musical, right? not in this case. luckily they were half talking/half singing in rhyme most of the time, but when they did sing it made me cringe. especially when they attempted to sing in harmony. and that just addresses the music. some of the acting was pretty good, but a lot of the dialog was terrible, as well as most of the scenes. they obviously didn't have enough coverage on the scenes, or they just had a bad editor, because they consistently jumped the line and used terrible choices while cutting the film. at least the director was willing to admit that no one wanted the script until they added the hook of making it a musical. i hope the investors make sure someone can write music before making the same mistake again.\n"
     ]
    }
   ],
   "source": [
    "with open(\"imdb_train.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "random.seed(10) # Seed to replicate same scenario for development\n",
    "random.shuffle(data) # Shuffle data \n",
    "\n",
    "# Preview of data\n",
    "print(\"class label:\", data[0][\"class\"])\n",
    "print(\"text:\", data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate texts and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of texts: 25000\n",
      "Amount of labels 25000\n",
      "\n",
      "neg the single worst film i've ever seen in a theater....\n",
      "pos I think the reason for all the opinionated diarrhe...\n",
      "neg This movie is horrible! It rivals \\Ishtar\\\" in the...\n",
      "neg This may not be the worst comedy of all time, but ...\n",
      "pos I found this film to funny from the start. John Wa...\n",
      "pos The problem is that the movie rode in on the coatt...\n",
      "neg I was so looking forward to seeing this when it wa...\n",
      "neg I actually saw this movie in the theater back in i...\n",
      "neg blows my mind how this movie got made. i watched i...\n",
      "neg Amateurish in the extreme. Camera work especially ...\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts and labels into separate lists\n",
    "texts=[d[\"text\"] for d in data]\n",
    "labels=[d[\"class\"] for d in data]\n",
    "print(\"Amount of texts:\", len(texts))\n",
    "print(\"Amount of labels\", len(labels))\n",
    "print()\n",
    "for label, text in list(zip(labels, texts))[:10]:\n",
    "    print(label, text[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test sklearn’s TfidfVectorizer\n",
    "\n",
    "**Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(texts, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method for easier showing results in changes of n-grams and C-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(ngramRange, maxFeatures, cValue, vectorizerType):\n",
    "    # Change vectorizer type based on variable\n",
    "    if(vectorizerType == \"Count\"):\n",
    "        vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    if(vectorizerType == \"Idf\"):\n",
    "        vectorizer = TfidfVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    \n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    print(\"Vectorizer type={0}, C={1}, n-gram={2}\".format(vectorizerType, cValue, ngramRange))\n",
    "    print(\"DEV\", classifier.score(feature_matrix_dev, dev_labels))\n",
    "    print(\"TRAIN\", classifier.score(feature_matrix_train, train_labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.87\n",
      "TRAIN 0.89605\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.886\n",
      "TRAIN 0.95755\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8718\n",
      "TRAIN 0.99635\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8568\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Idf, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.8372\n",
      "TRAIN 0.8494\n",
      "\n",
      "Vectorizer type=Idf, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8532\n",
      "TRAIN 0.86915\n",
      "\n",
      "Vectorizer type=Idf, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.884\n",
      "TRAIN 0.9237\n",
      "\n",
      "Vectorizer type=Idf, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8942\n",
      "TRAIN 0.9838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Idf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing TfidfVectorizer and CountVectorizer when changing C value \n",
    "\n",
    "First thing I noticed was that the classification results where very similar. The Count Vectorizers dev and train results are higher on a lower C value like 0.0005. When the C value is increased the Count Vectorizers Train rises to 0.95 very fast and even to 1.0 meanwhile the dev results go up to 0.88 and down to 0.86 when C value is 0.5. The optimal C value for the count vectorizer is probably around 0.005 where the data has not been overfitted to the train data. \n",
    "\n",
    "As mentioned above the Count vectorizers results where whigher on a lower C value. The Tfidf Vectorizer with a C value of 0.0005 has results around 0.84 on dev and train. When the C Value is increased, both the dev and train results increase steadily. Only after a C value as high as 0.5 is where the dev and train start to separate eachother. I'd say that the optimal C value for the Tfidf Vectorizer is around 0.05 because of diminishing returns on the dev result. This method seems to do a better job with not overfitting with the data. \n",
    "\n",
    "The Tfidf Vectorizer when it is run with an optimal C value has better dev results than Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test different lengths of n-grams in the CountVectorizer on the IMDB data\n",
    "\n",
    "**Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?**\n",
    "\n",
    "\n",
    "Lets start by looking att the results of different n-grams and try to find their optimal C values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.87\n",
      "TRAIN 0.89605\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.886\n",
      "TRAIN 0.95755\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8718\n",
      "TRAIN 0.99635\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8568\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 2)\n",
      "DEV 0.8814\n",
      "TRAIN 0.9338\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 2)\n",
      "DEV 0.8994\n",
      "TRAIN 0.9951\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.8906\n",
      "TRAIN 1.0\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 2)\n",
      "DEV 0.8866\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 3)\n",
      "DEV 0.884\n",
      "TRAIN 0.93995\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 3)\n",
      "DEV 0.8988\n",
      "TRAIN 0.9969\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.8928\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.5, n-gram=(1, 3)\n",
      "DEV 0.8904\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(2, 3)\n",
      "DEV 0.8572\n",
      "TRAIN 0.91995\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(2, 3)\n",
      "DEV 0.8758\n",
      "TRAIN 0.995\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.868\n",
      "TRAIN 0.99995\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(2, 3)\n",
      "DEV 0.8632\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of different n-grams\n",
    "\n",
    "When the n-grams are increased the C Value does not need to be that big. The Classifiers results are almost optimal at a value of 0.0005. The n-grams become very fast overfitted to the  train data if the C value is too high. I'd say the most optimal was an n-gram range of (1,2) and the C value as 0.005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "Lets create a mehtod for showing the most significant features. After that we can look at the n-gram ranges of (1,2) and (2,3) since (1,1) will only consist of 1 lenght features.\n",
    "\n",
    "### Create method for showing significant Features based on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSignificantFeatures(maxFeatures, ngramRange, cValue):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    index2feature={}\n",
    "    for feature,idx in vectorizer.vocabulary_.items():\n",
    "        assert idx not in index2feature #This really should hold\n",
    "        index2feature[idx]=feature\n",
    "    \n",
    "    indices=numpy.argsort(classifier.coef_[0])\n",
    "    print(indices)\n",
    "    for idx in indices[:30]:\n",
    "        print(index2feature[idx])\n",
    "    print(\"-------------------------------\")\n",
    "    for idx in indices[::-1][:30]:\n",
    "        print(index2feature[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (1,2)\n",
      "[98605  9932 13398 ... 26292 63521 27674]\n",
      "worst\n",
      "awful\n",
      "boring\n",
      "poor\n",
      "poorly\n",
      "waste\n",
      "disappointing\n",
      "bad\n",
      "the worst\n",
      "disappointment\n",
      "dull\n",
      "stupid\n",
      "terrible\n",
      "lacks\n",
      "horrible\n",
      "unfortunately\n",
      "worse\n",
      "fails\n",
      "mess\n",
      "lame\n",
      "ridiculous\n",
      "oh\n",
      "not even\n",
      "badly\n",
      "than this\n",
      "avoid\n",
      "nothing\n",
      "not worth\n",
      "annoying\n",
      "forgettable\n",
      "-------------------------------\n",
      "excellent\n",
      "perfect\n",
      "enjoyable\n",
      "great\n",
      "fun\n",
      "amazing\n",
      "wonderful\n",
      "superb\n",
      "better than\n",
      "must see\n",
      "well worth\n",
      "today\n",
      "loved\n",
      "incredible\n",
      "rare\n",
      "refreshing\n",
      "enjoyed\n",
      "the best\n",
      "love this\n",
      "10 10\n",
      "to all\n",
      "expecting\n",
      "perfectly\n",
      "beautiful\n",
      "very good\n",
      "gem\n",
      "fascinating\n",
      "surprisingly\n",
      "don want\n",
      "highly\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (1,2)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (2,3)\n",
      "[81627 93075 53648 ... 39671 94121 52090]\n",
      "the worst\n",
      "waste of\n",
      "not even\n",
      "than this\n",
      "of the worst\n",
      "at best\n",
      "fails to\n",
      "bad movie\n",
      "at all\n",
      "not worth\n",
      "bad acting\n",
      "unless you\n",
      "is bad\n",
      "not good\n",
      "boring and\n",
      "how bad\n",
      "not funny\n",
      "so bad\n",
      "worse than\n",
      "even worse\n",
      "should have\n",
      "bad and\n",
      "unfortunately the\n",
      "the original\n",
      "none of\n",
      "worst movie\n",
      "way too\n",
      "just not\n",
      "better to\n",
      "very disappointed\n",
      "-------------------------------\n",
      "must see\n",
      "well worth\n",
      "is great\n",
      "loved it\n",
      "highly recommended\n",
      "the best\n",
      "an excellent\n",
      "10 10\n",
      "is excellent\n",
      "enjoyed it\n",
      "was great\n",
      "my favorite\n",
      "loved this\n",
      "definitely worth\n",
      "highly recommend\n",
      "great movie\n",
      "very good\n",
      "enjoyed this\n",
      "love this\n",
      "to all\n",
      "very well\n",
      "an amazing\n",
      "on dvd\n",
      "of the best\n",
      "is wonderful\n",
      "was excellent\n",
      "great job\n",
      "fun and\n",
      "great film\n",
      "and enjoy\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (2,3)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most significant n-grams\n",
    "\n",
    "It seems to be that the longer the featue, the more unique and more rare it is. If we look at the n-gram range of (1,2), then the most significant features have some words that are 2 words long. The majority of the features are still of one length. \n",
    "\n",
    "If we look at the n-gram range (1,3), then this proves also our point. There are some features that consist of 3 words, but most of the features are 2 words. The most common 3 words consists of the words \"of the worst/best\". \n",
    "\n",
    "It is rare that longer sentences would occur several times in normal text or literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train an SVM classifier for language recognition\n",
    "\n",
    "**In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create methods for reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openTextFile(lang, section):\n",
    "    path = \"./language-identification/{0}_{1}.txt\".format(lang, section)\n",
    "    textList = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            obj = {'lang': lang,\n",
    "               'text': line.strip()\n",
    "            }\n",
    "            textList.append(obj)\n",
    "            \n",
    "    return textList\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateLabelText(data):\n",
    "    texts=[d[\"text\"] for d in data]\n",
    "    labels=[d[\"lang\"] for d in data]\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLangFiles(languages):\n",
    "    trainData = []\n",
    "    develData = []\n",
    "    testData = []\n",
    "    \n",
    "    for lang in languages:\n",
    "        trainData.extend(openTextFile(lang, 'train'))\n",
    "        develData.extend(openTextFile(lang, 'devel'))\n",
    "        testData.extend(openTextFile(lang, 'test'))\n",
    "\n",
    "    # Shuffle Data\n",
    "    random.seed(10) # Seed to replicate same scenario for development\n",
    "    random.shuffle(trainData) # Shuffle data \n",
    "    random.shuffle(develData) # Shuffle data \n",
    "    random.shuffle(testData) # Shuffle data \n",
    "    \n",
    "    # Separate labels from text\n",
    "    trainTexts, trainLabels = separateLabelText(trainData)\n",
    "    develTexts, develLabels = separateLabelText(develData)\n",
    "    testTexts, testLabels = separateLabelText(testData)\n",
    "\n",
    "        \n",
    "    return trainTexts, trainLabels, develTexts, develLabels, testTexts, testLabels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature matrix and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'et', 'fi', 'pt']\n",
    "# Read in the texts and labels\n",
    "lang_text_train, lang_label_train, lang_text_dev, lang_label_dev, lang_text_test, lang_label_test = loadLangFiles(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n"
     ]
    }
   ],
   "source": [
    "lang_vectorizer = TfidfVectorizer(max_features = 100000, binary=True, ngram_range = (1,1))\n",
    "lang_feature_matrix_train = lang_vectorizer.fit_transform(lang_text_train)\n",
    "lang_feature_matrix_dev = lang_vectorizer.transform(lang_text_dev)\n",
    "lang_feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "\n",
    "lang_classifier = sklearn.svm.LinearSVC(C = 0.05, verbose = 0)\n",
    "lang_classifier.fit(lang_feature_matrix_train, lang_label_train)\n",
    "\n",
    "print(\"DEV\", lang_classifier.score(lang_feature_matrix_dev, lang_label_dev))\n",
    "print(\"TEST\", lang_classifier.score(lang_feature_matrix_test, lang_label_test))\n",
    "print(\"TRAIN\", lang_classifier.score(lang_feature_matrix_train, lang_label_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLang(text, vectorizer, classifier):\n",
    "    data = vectorizer.transform([text])\n",
    "    \n",
    "    prediction = classifier.predict(data)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n",
      "['es']\n",
      "['et']\n",
      "['fi']\n",
      "['pt']\n"
     ]
    }
   ],
   "source": [
    "predictLang(\"Today is a nice day.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Estas obras son realizadas con libros, álbumes de música o periódicos como soporte.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Publik teeb nii mitu korda ja on juba üles köetud.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Tänään on mahti päivä mennä kävelylle.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Conseguir um bom exclusivo pode significar a entrada de milhões de dólares em publicidade.\", lang_vectorizer, lang_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Toy around with features, especially the ngram_range and analyzer parameters\n",
    "\n",
    "**If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method for easier comparisons of changes in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLangClassifier(ngramRange, maxFeatures, cValue, analyzerParam):\n",
    "    lang_vectorizer = TfidfVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange, analyzer = analyzerParam)\n",
    "    lang_feature_matrix_train = lang_vectorizer.fit_transform(lang_text_train)\n",
    "    lang_feature_matrix_dev = lang_vectorizer.transform(lang_text_dev)\n",
    "    lang_feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "\n",
    "    lang_classifier = sklearn.svm.LinearSVC(C = cValue, verbose = 0)\n",
    "    lang_classifier.fit(lang_feature_matrix_train, lang_label_train)\n",
    "\n",
    "    print(\"analyzer={0}, C={1}, n-gram={2}\".format(analyzerParam, cValue, ngramRange))\n",
    "    print(\"DEV\", lang_classifier.score(lang_feature_matrix_dev, lang_label_dev))\n",
    "    print(\"TEST\", lang_classifier.score(lang_feature_matrix_test, lang_label_test))\n",
    "    print(\"TRAIN\", lang_classifier.score(lang_feature_matrix_train, lang_label_train))\n",
    "    print()\n",
    "    \n",
    "    return lang_vectorizer, lang_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer = \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=word, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.9366\n",
      "TEST 0.9406\n",
      "TRAIN 0.9968\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.937\n",
      "TEST 0.9392\n",
      "TRAIN 0.993\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(2, 2)\n",
      "DEV 0.759\n",
      "TEST 0.7616\n",
      "TRAIN 0.9842\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.7484\n",
      "TEST 0.7522\n",
      "TRAIN 0.9796\n",
      "\n",
      "analyzer=word, C=0.05, n-gram=(3, 3)\n",
      "DEV 0.398\n",
      "TEST 0.4048\n",
      "TRAIN 0.9734\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (3,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer = \"char\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=char, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8896\n",
      "TEST 0.8864\n",
      "TRAIN 0.8978\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.9736\n",
      "TEST 0.9762\n",
      "TRAIN 0.983\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.979\n",
      "TEST 0.9826\n",
      "TRAIN 0.9922\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(2, 2)\n",
      "DEV 0.972\n",
      "TEST 0.9756\n",
      "TRAIN 0.9822\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.979\n",
      "TEST 0.9826\n",
      "TRAIN 0.9928\n",
      "\n",
      "analyzer=char, C=0.05, n-gram=(3, 3)\n",
      "DEV 0.9782\n",
      "TEST 0.9832\n",
      "TRAIN 0.994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "createLangClassifier(\n",
    "    ngramRange = (3,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"char\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of classification \n",
    "\n",
    "When increasing the word feature count it should not have an big effect on the result. To me it is very understandable that the uniqueness of the 2 word or longer features would not have an effect on the classification. I still am curious why when using the word analyzer, that the classification would fail. When comparing Finnish to Estonian, the languages might look very similar, but there are major differences. My bet is that when the lenght of a document is short, the classifier might find it hard to find the correct language because the same words might appear in other languages.\n",
    "\n",
    "When using characters as features the results are quite different. The singel character feature works quite well because of languages having their own letters. \n",
    "When the feature lenght is increased, the accuracy is immensely increased. Every language has its own gramar rules. This will make some letter frequencies more common. \n",
    "\n",
    "To get the best accuracy, one could combine the score from words and from the characters and take the average value of that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find misclassified documents\n",
    "\n",
    "I want to find out why the classifier fails when using words as features. Lets look at the confusion matrix and some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer=word, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.934\n",
      "TEST 0.9392\n",
      "TRAIN 0.9878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect, classifer  = createLangClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.05,\n",
    "    analyzerParam = \"word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "en es et fi pt\n",
      "[[906   3   4  78   9]\n",
      " [  1 981   1   8   9]\n",
      " [  2   3 911  84   0]\n",
      " [  3   3  34 959   1]\n",
      " [  2   6   1  52 939]]\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_test = lang_vectorizer.transform(lang_text_test)\n",
    "predictions_test=classifer.predict(feature_matrix_test)\n",
    "print(\"confusion matrix\")\n",
    "print('en', 'es', 'et', 'fi', 'pt')\n",
    "print(sklearn.metrics.confusion_matrix(lang_label_test,predictions_test, labels=['en', 'es', 'et', 'fi', 'pt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix goes from EN -> ES -> ET -> FI -> PT.\n",
    "\n",
    "Most of the missclassifications seem to be around Finnish. The model might have been overfitted for finnish when comparing english text. Meanwhile the confusion in classification of Estonian and Finnish texts are understandable. Gramatically they are very similar. Although, the classifier seems to classify more on the Finnish side than estonian. Even some Portugese text have been classified as Finnish. I strongly believe the documents to contain words similar to Finnish language and be short texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the missclassified documents\n",
    "\n",
    "Lets create a class that contains the info needed for our predictions and save them to a list. After that we can look more closely what might have gone wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangPred:\n",
    "    \n",
    "    def __init__(self, lang, pred, text):\n",
    "        self.lang = lang\n",
    "        self.pred = pred\n",
    "        self.text = text\n",
    "    \n",
    "    def showPred(self):\n",
    "        print(\"Lang= {0}\".format(self.lang)) \n",
    "        print(\"Prediction= {0}\".format(self.pred)) \n",
    "        print(\"Text= {0}\".format(self.text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassifed = []\n",
    "\n",
    "incre = 0 \n",
    "for text in lang_text_test:\n",
    "    data = vect.transform([text])\n",
    "    prediction = classifer.predict(data)\n",
    "    \n",
    "    if prediction != lang_label_test[incre]:\n",
    "        missclassifed.append(LangPred(lang_label_test[incre], prediction, text))\n",
    "        \n",
    "    incre += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets analyse some misscalssifed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang= en\n",
      "Prediction= ['fi']\n",
      "Text= 09/16/99 09:48 PM\n",
      "Lang= et\n",
      "Prediction= ['en']\n",
      "Text= \" More\"!\n",
      "Lang= pt\n",
      "Prediction= ['fi']\n",
      "Text= Harmonização« inoportuna»\n",
      "Lang= en\n",
      "Prediction= ['fi']\n",
      "Text= Fascinating.\n",
      "Lang= pt\n",
      "Prediction= ['fi']\n",
      "Text= E o Brasil?\n",
      "Lang= et\n",
      "Prediction= ['fi']\n",
      "Text= “ Jansu on mõnus ja heatahtlik mutrike, huvitav nähtus tantsumaailmas.”\n"
     ]
    }
   ],
   "source": [
    "missclassifed[0].showPred()\n",
    "missclassifed[5].showPred()\n",
    "missclassifed[10].showPred()\n",
    "missclassifed[15].showPred()\n",
    "missclassifed[20].showPred()\n",
    "missclassifed[21].showPred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting a few of the missclassifed documents, we can se that my theory is quite on point. The texts are mostly short and can easily be missclassfied. The first one contains only numbers and should probably be parsed out of the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BONUS: ......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
