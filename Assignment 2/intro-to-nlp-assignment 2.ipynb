{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP: Assignment 2 \n",
    "\n",
    "## Assignment on Text Classification and Sequence Labeling\n",
    "\n",
    "### Description of Assignment 2\n",
    "\n",
    "This assignment relates to the Text classification and Sequence labeling themes of the introduction to NLP (courses Deskriptiv analytik / Machine learning for descriptive problems), and will focus on gaining some practical, hands-on experience in building and training simple models for these tasks.\n",
    "\n",
    "The assignment is handed in as a Jupyternotebook (or a PDF render thereof) containing the code used to solve the problem, output presenting the results, and, most importantly, notes that present the students' conclusions and answer questions posed in the assignment.\n",
    "\n",
    "**Assignment steps/Questions:**\n",
    "\n",
    "1. Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?\n",
    "\n",
    "2. Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "3. In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.\n",
    "\n",
    "4. If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?\n",
    "\n",
    "5. **BONUS** On the address universaldependencies.org, you will find datasets for a bunch of languages. These come in an easy-to-parse, well-documented format. Pick one language that interests you, and one treebank for that language, and try to builda POS tagger for this language. You can use the 4th column “UPOS” [https://universaldependencies.org/format.html](https://universaldependencies.org/format.html) Report on your findings. If you have extra time, try to experiment with various features and see if you can make your accuracy go up. You can check here [https://universaldependencies.org/conll18/results-upos.html](https://universaldependencies.org/conll18/results-upos.html) what the state of the art roughly is for your selected language and treebank. Did you come close?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: neg\n",
      "text: the single worst film i've ever seen in a theater. i saw this film at the austin film festival in 2004, and it blew my mind that this film was accepted to a festival. it was an interesting premise, and seemed like it could go somewhere, but just fell apart every time it tried to do anything. first of all, if you're going to do a musical, find someone with musical talent. the music consisted of cheesy piano playing that sounded like they were playing it on a stereo in the room they were filming. the lyrics were terribly written, and when they weren't obvious rhymes, they were groan-inducing rhymes that showed how far they were stretching to try to make this movie work. and you'd think you'd find people who could sing when making a musical, right? not in this case. luckily they were half talking/half singing in rhyme most of the time, but when they did sing it made me cringe. especially when they attempted to sing in harmony. and that just addresses the music. some of the acting was pretty good, but a lot of the dialog was terrible, as well as most of the scenes. they obviously didn't have enough coverage on the scenes, or they just had a bad editor, because they consistently jumped the line and used terrible choices while cutting the film. at least the director was willing to admit that no one wanted the script until they added the hook of making it a musical. i hope the investors make sure someone can write music before making the same mistake again.\n"
     ]
    }
   ],
   "source": [
    "with open(\"imdb_train.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "random.seed(10) # Seed to replicate same scenario for development\n",
    "random.shuffle(data) # Shuffle data \n",
    "\n",
    "# Preview of data\n",
    "print(\"class label:\", data[0][\"class\"])\n",
    "print(\"text:\", data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate texts and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of texts: 25000\n",
      "Amount of labels 25000\n",
      "\n",
      "neg the single worst film i've ever seen in a theater....\n",
      "pos I think the reason for all the opinionated diarrhe...\n",
      "neg This movie is horrible! It rivals \\Ishtar\\\" in the...\n",
      "neg This may not be the worst comedy of all time, but ...\n",
      "pos I found this film to funny from the start. John Wa...\n",
      "pos The problem is that the movie rode in on the coatt...\n",
      "neg I was so looking forward to seeing this when it wa...\n",
      "neg I actually saw this movie in the theater back in i...\n",
      "neg blows my mind how this movie got made. i watched i...\n",
      "neg Amateurish in the extreme. Camera work especially ...\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts and labels into separate lists\n",
    "texts=[d[\"text\"] for d in data]\n",
    "labels=[d[\"class\"] for d in data]\n",
    "print(\"Amount of texts:\", len(texts))\n",
    "print(\"Amount of labels\", len(labels))\n",
    "print()\n",
    "for label, text in list(zip(labels, texts))[:10]:\n",
    "    print(label, text[:50] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test sklearn’s TfidfVectorizer\n",
    "\n",
    "**Test sklearn’s TfidfVectorizer in place of CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(texts, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create method for easier showing results in changes of n-grams and C-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(ngramRange, maxFeatures, cValue, vectorizerType):\n",
    "    # Change vectorizer type based on variable\n",
    "    if(vectorizerType == \"Count\"):\n",
    "        vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    if(vectorizerType == \"Idf\"):\n",
    "        vectorizer = TfidfVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    \n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    print(\"Vectorizer type={0}, C={1}, n-gram={2}\".format(vectorizerType, cValue, ngramRange))\n",
    "    print(\"DEV\", classifier.score(feature_matrix_dev, dev_labels))\n",
    "    print(\"TRAIN\", classifier.score(feature_matrix_train, train_labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.8688\n",
      "TRAIN 0.89385\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8812\n",
      "TRAIN 0.95645\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8728\n",
      "TRAIN 0.9959\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8546\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Idf, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.84\n",
      "TRAIN 0.84545\n",
      "\n",
      "Vectorizer type=Idf, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.856\n",
      "TRAIN 0.8677\n",
      "\n",
      "Vectorizer type=Idf, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.884\n",
      "TRAIN 0.9218\n",
      "\n",
      "Vectorizer type=Idf, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8936\n",
      "TRAIN 0.98515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Idf\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Idf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing TfidfVectorizer and CountVectorizer when changing C value \n",
    "\n",
    "First thing I noticed was that the classification results where very similar. The Count Vectorizers dev and train results are higher on a lower C value like 0.0005. When the C value is increased the Count Vectorizers Train rises to 0.95 very fast and even to 1.0 meanwhile the dev results go up to 0.88 and down to 0.86 when C value is 0.5. The optimal C value for the count vectorizer is probably around 0.005 where the data has not been overfitted to the train data. \n",
    "\n",
    "As mentioned above the Count vectorizers results where whigher on a lower C value. The Tfidf Vectorizer with a C value of 0.0005 has results around 0.84 on dev and train. When the C Value is increased, both the dev and train results increase steadily. Only after a C value as high as 0.5 is where the dev and train start to separate eachother. I'd say that the optimal C value for the Tfidf Vectorizer is around 0.05 because of diminishing returns on the dev result. This method seems to do a better job with not overfitting with the data. \n",
    "\n",
    "The Tfidf Vectorizer when it is run with an optimal C value has better dev results than Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test different lengths of n-grams in the CountVectorizer on the IMDB data\n",
    "\n",
    "**Test different lengths of n-grams in the CountVectorizer on the IMDB data. Do you see any difference in the classification results or the optimal C value ? Do these n-grams show up also in the list of most significant positive/negative features?**\n",
    "\n",
    "\n",
    "Lets start by looking att the results of different n-grams and try to find their optimal C values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 1)\n",
      "DEV 0.8688\n",
      "TRAIN 0.89385\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 1)\n",
      "DEV 0.8812\n",
      "TRAIN 0.95645\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 1)\n",
      "DEV 0.8728\n",
      "TRAIN 0.9959\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 1)\n",
      "DEV 0.8546\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,1), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 2)\n",
      "DEV 0.8868\n",
      "TRAIN 0.93355\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 2)\n",
      "DEV 0.8994\n",
      "TRAIN 0.99515\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 2)\n",
      "DEV 0.8916\n",
      "TRAIN 1.0\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 2)\n",
      "DEV 0.8898\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (1-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(1, 3)\n",
      "DEV 0.888\n",
      "TRAIN 0.9396\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(1, 3)\n",
      "DEV 0.8998\n",
      "TRAIN 0.997\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(1, 3)\n",
      "DEV 0.8912\n",
      "TRAIN 1.0\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(1, 3)\n",
      "DEV 0.8876\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (1,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer n-gram (2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer type=Count, C=0.0005, n-gram=(2, 3)\n",
      "DEV 0.8574\n",
      "TRAIN 0.9192\n",
      "\n",
      "Vectorizer type=Count, C=0.005, n-gram=(2, 3)\n",
      "DEV 0.8752\n",
      "TRAIN 0.9945\n",
      "\n",
      "Vectorizer type=Count, C=0.05, n-gram=(2, 3)\n",
      "DEV 0.8688\n",
      "TRAIN 1.0\n",
      "\n",
      "Vectorizer type=Count, C=0.5, n-gram=(2, 3)\n",
      "DEV 0.8622\n",
      "TRAIN 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.0005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.005, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.05, \n",
    "    vectorizerType = \"Count\"\n",
    ")\n",
    "createClassifier(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000, \n",
    "    cValue = 0.5, \n",
    "    vectorizerType = \"Count\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of different n-grams\n",
    "\n",
    "When the n-grams are increased the C Value does not need to be that big. The Classifiers results are almost optimal at a value of 0.0005. The n-grams become very fast overfitted to the  train data if the C value is too high. I'd say the most optimal was an n-gram range of (1,2) and the C value as 0.005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do these n-grams show up also in the list of most significant positive/negative features?\n",
    "\n",
    "Lets create a mehtod for showing the most significant features. After that we can look at the n-gram ranges of (1,2) and (2,3) since (1,1) will only consist of 1 lenght features.\n",
    "\n",
    "### Create method for showing significant Features based on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSignificantFeatures(maxFeatures, ngramRange, cValue):\n",
    "    \n",
    "    vectorizer = CountVectorizer(max_features = maxFeatures, binary=True, ngram_range = ngramRange)\n",
    "    feature_matrix_train = vectorizer.fit_transform(train_texts)\n",
    "    feature_matrix_dev = vectorizer.transform(dev_texts)\n",
    "    \n",
    "    classifier = sklearn.svm.LinearSVC(C =  cValue, verbose = 0)\n",
    "    classifier.fit(feature_matrix_train, train_labels)\n",
    "    \n",
    "    index2feature={}\n",
    "    for feature,idx in vectorizer.vocabulary_.items():\n",
    "        assert idx not in index2feature #This really should hold\n",
    "        index2feature[idx]=feature\n",
    "    \n",
    "    indices=numpy.argsort(classifier.coef_[0])\n",
    "    print(indices)\n",
    "    for idx in indices[:30]:\n",
    "        print(index2feature[idx])\n",
    "    print(\"-------------------------------\")\n",
    "    for idx in indices[::-1][:30]:\n",
    "        print(index2feature[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (1,2)\n",
      "[98580  9852 13424 ... 34446 63258 27178]\n",
      "worst\n",
      "awful\n",
      "boring\n",
      "waste\n",
      "terrible\n",
      "disappointing\n",
      "dull\n",
      "disappointment\n",
      "bad\n",
      "poorly\n",
      "the worst\n",
      "poor\n",
      "unfortunately\n",
      "lacks\n",
      "horrible\n",
      "fails\n",
      "worse\n",
      "mess\n",
      "stupid\n",
      "avoid\n",
      "ridiculous\n",
      "not good\n",
      "lame\n",
      "badly\n",
      "oh\n",
      "save\n",
      "unfunny\n",
      "waste of\n",
      "than this\n",
      "laughable\n",
      "-------------------------------\n",
      "excellent\n",
      "perfect\n",
      "great\n",
      "amazing\n",
      "enjoyable\n",
      "superb\n",
      "wonderful\n",
      "loved\n",
      "today\n",
      "must see\n",
      "rare\n",
      "bit\n",
      "fun\n",
      "incredible\n",
      "very good\n",
      "refreshing\n",
      "fantastic\n",
      "gem\n",
      "better than\n",
      "wonderfully\n",
      "the best\n",
      "well worth\n",
      "liked\n",
      "highly\n",
      "subtle\n",
      "enjoyed\n",
      "beautiful\n",
      "is great\n",
      "pretty good\n",
      "fascinating\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (1,2)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (1,2), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram (2,3)\n",
      "[81564 93017 53601 ... 75151 39589 52018]\n",
      "the worst\n",
      "waste of\n",
      "not even\n",
      "than this\n",
      "of the worst\n",
      "at best\n",
      "not good\n",
      "bad acting\n",
      "fails to\n",
      "boring and\n",
      "unless you\n",
      "at all\n",
      "not worth\n",
      "bad movie\n",
      "so bad\n",
      "your time\n",
      "none of\n",
      "supposed to\n",
      "is awful\n",
      "is terrible\n",
      "worst movie\n",
      "might have\n",
      "very bad\n",
      "better to\n",
      "bad and\n",
      "how bad\n",
      "avoid this\n",
      "not funny\n",
      "is bad\n",
      "looks like\n",
      "-------------------------------\n",
      "must see\n",
      "is great\n",
      "the best\n",
      "loved it\n",
      "well worth\n",
      "was great\n",
      "highly recommended\n",
      "my favorite\n",
      "great movie\n",
      "loved this\n",
      "is amazing\n",
      "is excellent\n",
      "very good\n",
      "highly recommend\n",
      "enjoyed this\n",
      "very well\n",
      "10 10\n",
      "great job\n",
      "enjoyed it\n",
      "love this\n",
      "an excellent\n",
      "on dvd\n",
      "definitely worth\n",
      "it great\n",
      "of the best\n",
      "was excellent\n",
      "fun and\n",
      "is perfect\n",
      "is wonderful\n",
      "love it\n"
     ]
    }
   ],
   "source": [
    "print(\"N-gram (2,3)\")\n",
    "showSignificantFeatures(\n",
    "    ngramRange = (2,3), \n",
    "    maxFeatures = 100000,\n",
    "    cValue = 0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most significant n-grams\n",
    "\n",
    "It seems to be that the longer the featue, the more unique and more rare it is. If we look at the n-gram range of (1,2), then the most significant features have some words that are 2 words long. The majority of the features are still of one length. \n",
    "\n",
    "If we look at the n-gram range (1,3), then this proves also our point. There are some features that consist of 3 words, but most of the features are 2 words. The most common 3 words consists of the words \"of the worst/best\". \n",
    "\n",
    "It is rare that longer sentences would occur several times in normal text or literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train an SVM classifier for language recognition\n",
    "\n",
    "**In the data package for the course [http://dl.turkunlp.org/intro-to-nlp.tar.gz](http://dl.turkunlp.org/intro-to-nlp.tar.gz), the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create methods for reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openTextFile(lang, section):\n",
    "    path = \"./language-identification/{0}_{1}.txt\".format(lang, section)\n",
    "    textList = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            obj = {'lang': lang,\n",
    "               'text': line.strip()\n",
    "            }\n",
    "            textList.append(obj)\n",
    "            \n",
    "    return textList\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateLabelText(data):\n",
    "    texts=[d[\"text\"] for d in data]\n",
    "    labels=[d[\"lang\"] for d in data]\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLangFiles(languages):\n",
    "    trainData = []\n",
    "    develData = []\n",
    "    testData = []\n",
    "    \n",
    "    for lang in languages:\n",
    "        trainData.extend(openTextFile(lang, 'train'))\n",
    "        develData.extend(openTextFile(lang, 'devel'))\n",
    "        testData.extend(openTextFile(lang, 'test'))\n",
    "\n",
    "    # Shuffle Data\n",
    "    random.seed(10) # Seed to replicate same scenario for development\n",
    "    random.shuffle(trainData) # Shuffle data \n",
    "    random.shuffle(develData) # Shuffle data \n",
    "    random.shuffle(testData) # Shuffle data \n",
    "    \n",
    "    # Separate labels from text\n",
    "    trainTexts, trainLabels = separateLabelText(trainData)\n",
    "    develTexts, develLabels = separateLabelText(develData)\n",
    "    testTexts, testLabels = separateLabelText(testData)\n",
    "\n",
    "        \n",
    "    return trainTexts, trainLabels, develTexts, develLabels, testTexts, testLabels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature matrix and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'et', 'fi', 'pt']\n",
    "# Read in the texts and labels\n",
    "lang_text_train, lang_label_train, lang_text_dev, lang_label_dev, lang_text_test, lang_label_test = loadLangFiles(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV 0.934\n",
      "TRAIN 0.9878\n"
     ]
    }
   ],
   "source": [
    "lang_vectorizer = TfidfVectorizer(max_features = 100000, binary=True, ngram_range = (1,1))\n",
    "lang_feature_matrix_train = lang_vectorizer.fit_transform(lang_text_train)\n",
    "lang_feature_matrix_dev = lang_vectorizer.transform(lang_text_dev)\n",
    "\n",
    "lang_classifier = sklearn.svm.LinearSVC(C = 0.05, verbose = 0)\n",
    "lang_classifier.fit(lang_feature_matrix_train, lang_label_train)\n",
    "\n",
    "print(\"DEV\", lang_classifier.score(lang_feature_matrix_dev, lang_label_dev))\n",
    "print(\"TRAIN\", lang_classifier.score(lang_feature_matrix_train, lang_label_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLang(text, vectorizer, classifier):\n",
    "    data = vectorizer.transform([text])\n",
    "    \n",
    "    prediction = classifier.predict(data)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n",
      "['es']\n",
      "['et']\n",
      "['fi']\n",
      "['pt']\n"
     ]
    }
   ],
   "source": [
    "predictLang(\"Today is a nice day.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Estas obras son realizadas con libros, álbumes de música o periódicos como soporte.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Publik teeb nii mitu korda ja on juba üles köetud.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Tänään on mahti päivä mennä kävelylle.\", lang_vectorizer, lang_classifier)\n",
    "predictLang(\"Conseguir um bom exclusivo pode significar a entrada de milhões de dólares em publicidade.\", lang_vectorizer, lang_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Toy around with features, especially the ngram_range and analyzer parameters\n",
    "\n",
    "**If you completed (3), toy around with features, especially the ngram_range and analyzer parameters, which allow you to test classification based on character ngrams of various lengths (not only word n-grams). Gain some insight in to the accuracy of the classifier with different features, and try to identify misclassified documents -why do you think they were misclassified?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
